---
layout: page
title: Parallel Computing on HPC systems
subtitle: TBD
minutes: 60
---
> ##  Outline {.objectives}
> * Extensions to 2D and 3D
> * Cyclic block distribution
> * Stuff we have not touched
> * Higher-Level packages and libraries

## Finite differences in more than 1D

The extension of the simple approximation of the 1D heat equation
to more than 1 dimension is rather straight-forward. Assuming that we have the same heat conductivity in both directions, and still ignoring any source terms we have:

du/dt = k * (d2u/dx^2 + d2u/dz^2)

which can be discretized the same way as in one direction, just yielding a somewhat longer expresssion

[u(n+1,i,j) - u(n,i,j)]/dt =
k * {[u(n,i,j+1)-2*u(n,i,j)+u(n,i,j-1)]/(dx)^2} +
     [u(n,i+1,j)-2*u(n,i,j)+u(n,i-1,j)]/(dz)^2}

This assumes an isotropic Cartesian grid, and since it's best to use
the same spacing in both direction, we may as well set dx=dz=d. The
indices j and i are counting the gridpoints in x and z direction,
respectively. Everything else is like in 1D. In the case of three
dimensions we'd have three terms and indices, but the basic form is
the same.

If the conductivity term k is not the same for the directions, or if
the grid is not chosen equal in all directions, things get more
complicated. Also, the approximation of the Laplacian by a simple
thre-point formula may not be accurate enough. In several dimensions
things may be inhomogeneous enough to warrant a different coordinate
system than a simple Cartesian one. The situation may make itr
impossible to properly separate variables, etc.

Still, the principle remains the same:

* approximate the continuous solution of the differential equation by discret points on a grid
* write the derivatives as an expression in terms of the gridpoints and nearby "neighbours"
* solve for the value of the gridpoints in the "next" time step
* initialize with the stareting distribution
* enforce boundary conditions at each step

## Domain decomposition in 2D and 3D

Domain decomposition is easy on a Cartesian grid. If the grid is
homogeneous, isotropoic, and Cartesian, we can limit the number of
data that have to be fetched in each step by, for instance distribute
the workload (and memory) only in one direction. For a 3D domain, this
corresponds to "slabs", for 2D it's "strips". For some cases, the Grid
can't be chosen to be homogeneous, though. For more complicated
domains or more sophisticated dynamics, there may be regions of "more
action" that have to be covered by a denser grid. Or worse, the time
scale of what's going on may be different. The potential for
complexity is unlimited.

Much of the effort of working with grid based methods in more complex
cases goes into constructing a grid that covers the regions and time
scales of interest in such a way that the computational load on each
of the processes is approximately equal. Because you are on a time
scale, the iterations are dependent, and you may have to "redraw" the
grid every so often to adapt to the changing circumstances.

## Cyclic Block distribution

(...to be added...)

## MPI issues we have not discussed

(...to be added...)

## Higher-level packages

(...to be added...)

